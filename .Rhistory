parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final ntree",
main_title = "Effect of ntree",
sub_title = "Final feature set: Mtry=10, full training set",
x_title = "Ntree values",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("50", "100", "150", "200", "250", "300",
"400", "500", "750", "1000"),
x_tick_breaks = c(50, 100, 150, 200, 250, 300, 400, 500, 750, 1000),
legend_title_parentheses=c(""),
newschool=TRUE,
bar_width = 1500,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_ntree[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final ntree",
main_title = "Effect of ntree",
sub_title = "Final feature set: Mtry=10, full training set",
x_title = "Ntree values",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("50", "100", "150", "200", "250", "300",
"400", "500", "750", "1000"),
x_tick_breaks = c(50, 100, 150, 200, 250, 300, 400, 500, 750, 1000),
legend_title_parentheses=c(""),
newschool=TRUE,
bar_width = 1000,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
source('~/GitHub/Gradu/make_all_pics.R')
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_split[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of split size",
main_title = "Effect of training set size (in percentages)",
sub_title = "Final feature set: Ntree=250, mtry=10",
x_title = "",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "100%"),
x_tick_breaks = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100),
legend_title_parentheses=c(""),
newschool=TRUE,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
source('~/GitHub/Gradu/make_all_pics.R')
source('~/GitHub/Gradu/make_pic_comparison_lines.R')
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_split[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of split size",
main_title = "Effect of training set size (in percentages)",
sub_title = "Final feature set: Ntree=250, mtry=10",
x_title = "",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "100%"),
x_tick_breaks = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100),
legend_title_parentheses=c(""),
newschool=TRUE,
highlight_max = c(FALSE, FALSE, TRUE, TRUE),
plot_width = 1000)
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_mtry[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final mtry",
main_title = "Effect of mtry",
sub_title = "Final feature set: Ntree=250, full training set",
x_title = "Mtry value",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("3", "4", "5", "6", "7", "8", "9", "10", "11",
"12", "13", "14", "15", "16", "17", "18", "19", "20",
"25", "30", "35", "40", "45", "50"),
x_tick_breaks = c(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 35, 40, 45, 50),
legend_title_parentheses=c(""),
newschool=TRUE,
plot_width=1500,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_ntree[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final ntree",
main_title = "Effect of ntree",
sub_title = "Final feature set: Mtry=10, full training set",
x_title = "Ntree values",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("50", "100", "150", "200", "250", "300",
"400", "500", "750", "1000"),
x_tick_breaks = c(50, 100, 150, 200, 250, 300, 400, 500, 750, 1000),
legend_title_parentheses=c(""),
newschool=TRUE,
plot_width = 1000,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
source('~/GitHub/Gradu/make_all_pics.R')
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_split[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final split",
main_title = "Effect of training set size (in percentages)",
sub_title = "Final feature set: Ntree=250, mtry=10",
x_title = "",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "100%"),
x_tick_breaks = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100),
legend_title_parentheses=c(""),
newschool=TRUE,
highlight_max = c(FALSE, FALSE, TRUE, TRUE),
plot_width = 1000)
source('~/GitHub/Gradu/make_all_pics.R')
qqq <- get_varimp_ranks(filepath = outputpath, filenamestem = "basic_bow19_punctuation_varimp")
qqq <- get_varimp_ranks(filepath = outputpath, filenamestem = "basic_bow19_antique_varimp")
qqq <- get_varimp_ranks(filepath = outputpath, filenamestem = "basic_bow19_marc_varimp")
qqq <- get_varimp_ranks(filepath = outputpath, filenamestem = "basic_bow19_author_caret_ntree250_mtry10")
qqq <- get_varimp_ranks(filepath = outputpath, filenamestem = "basic_bow19_antique_caret_ntree250_mtry10")
source('~/GitHub/Gradu/make_pic_comparison_lines.R')
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_mtry[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final mtry",
main_title = "Effect of mtry",
sub_title = "Final feature set: Ntree=250, full training set",
x_title = "Mtry value",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("3", "4", "5", "6", "7", "8", "9", "10", "11",
"12", "13", "14", "15", "16", "17", "18", "19", "20",
"25", "30", "35", "40", "45", "50"),
x_tick_breaks = c(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 35, 40, 45, 50),
legend_title_parentheses=c(""),
newschool=TRUE,
plot_width=1500,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
source('~/GitHub/Gradu/make_pic_comparison_lines.R')
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_mtry[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final mtry",
main_title = "Effect of mtry",
sub_title = "Final feature set: Ntree=250, full training set",
x_title = "Mtry value",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("3", "4", "5", "6", "7", "8", "9", "10", "11",
"12", "13", "14", "15", "16", "17", "18", "19", "20",
"25", "30", "35", "40", "45", "50"),
x_tick_breaks = c(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 35, 40, 45, 50),
legend_title_parentheses=c(""),
newschool=TRUE,
plot_width=1500,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
source('~/GitHub/Gradu/make_pic_comparison_lines.R')
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_mtry[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final mtry",
main_title = "Effect of mtry",
sub_title = "Final feature set: Ntree=250, full training set",
x_title = "Mtry value",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("3", "4", "5", "6", "7", "8", "9", "10", "11",
"12", "13", "14", "15", "16", "17", "18", "19", "20",
"25", "30", "35", "40", "45", "50"),
x_tick_breaks = c(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 35, 40, 45, 50),
legend_title_parentheses=c(""),
newschool=TRUE,
plot_width=1500,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
make_pic_comparison_lines(filepath=outputpath,
inputfile_patterns = c("FINAL_ntree[0-9]+_confusionMatrix_combined_no_cutoff.txt") ,
parameter_names = c("precision", "recall", "balanced_accuracy", "F1"),
outputfile = "Effect of final ntree",
main_title = "Effect of ntree",
sub_title = "Final feature set: Mtry=10, full training set",
x_title = "Ntree values",
legend_labels = c("Precision", "Recall", "Balanced accuracy", "F1"),
x_tick_labels = c("50", "100", "150", "200", "250", "300",
"400", "500", "750", "1000"),
x_tick_breaks = c(50, 100, 150, 200, 250, 300, 400, 500, 750, 1000),
legend_title_parentheses=c(""),
newschool=TRUE,
plot_width = 1000,
highlight_max = c(FALSE, FALSE, TRUE, TRUE))
kb <- readRDS("../../../Työ/Kungliga/Aineisto/Kungliga/df.kungliga.Rds")
nrow(kb)
kb$height[1:10]
length(which(is.na(kb$height)))
length(which(is.na(kb$obl)))
length(which(is.na(kb$area)))
length(which(is.na(kb$width)))
length(which(is.na(kb$gatherings)))
length(which(kb$gatherings!="")))
length(which(kb$gatherings!=""))
kb$gatherings[1:10]
length(which(kb$gatherings!=NA))
length(which(kb$gatherings==NA))
length(which(is.na(kb$gatherings.original)))
kb$gatherings.original[1:10]
length(which(kb$gatherings.original!=NA))
unique(kb$gatherings)
length(which(as.character(kb$gatherings.original)!="NA"))
install_github("ropengov/bibliographica")
length(which(as.character(kb$gatherings)!="NA"))
length(which(as.character(kb$gatherings)!="NA" & kb$publication_decade < 1800))
length(which(kb$publication_decade < 1800))
for (i in seq(1400, 1900, 10)) {l <- length(which(as.character(kb$gatherings!="NA" & kb$publication_decade <= i))); m <- length(which(kb$publication_decade <= i)); print(i);print(l); print(m); print("-----")}
for (i in seq(1400, 1900, 10)) {l <- length(which(as.character(kb$gatherings)!="NA" & kb$publication_decade <= i))); m <- length(which(kb$publication_decade <= i)); print(i);print(l); print(m); print("-----")}
for (i in seq(1400, 1900, 10)) {l <- length(which(as.character(kb$gatherings)!="NA" & kb$publication_decade <= i)); m <- length(which(kb$publication_decade <= i)); print(i);print(l); print(m); print("-----")}
unique(as.character(kb$gatherings))
length(which(as.character(kb$gatherings=="8vo")))
length(which(as.character(kb$gatherings)=="8vo"))
length(which(as.character(kb$gatherings)=="8vo" & kb$publication_year <= 1830))
length(which(as.character(kb$gatherings)=="8vo" & kb$publication_year_from <= 1830))
length(which(as.character(kb$gatherings)=="8vo" & kb$publication_decade <= 1830))
length(which(as.character(kb$gatherings)=="8vo" & kb$publication_year == 1830))
names(kb)
"language" %in% names(kb)
kb[,c(1:97)] <- NULL
names(kb)
octavos <- which(as.character(kb$gatherings)=="8vo" & kb$publication_year == 1830))
octavos <- which(as.character(kb$gatherings)=="8vo" & kb$publication_year == 1830)
length(octavos)
nrow(octavos)
octavos[1]
octavos <- which(as.character(kb$gatherings)=="8vo" & kb$publication_year <= 1830)
length(octavos)
octavo_books <- kb[octavos,]
nrow(octavos)
nrow(octavo_books)
octavo_books[1,]
write.csv2(octavo_books, file = "C:/Users/Hege/Työ/Kungliga/Output/octavo_book_before_1831_in_kungliga.csv", sep = "\t", row.names = FALSE, col.names = TRUE, na = "", fileEncoding = "UTF-8")
warnings()
write.csv(octavo_books, file = "C:/Users/Hege/Työ/Kungliga/Output/octavo_book_before_1831_in_kungliga.csv", sep = "\t", row.names = FALSE, col.names = TRUE, na = "", fileEncoding = "UTF-8")
write.table(octavo_books, file = "C:/Users/Hege/Työ/Kungliga/Output/octavo_book_before_1831_in_kungliga.csv", sep = "\t", row.names = FALSE, col.names = TRUE, na = "", fileEncoding = "UTF-8")
length(which(as.character(kb$gatherings)=="8vo" & kb$publication_year <= 1830)) / length(which(kb$publication_year <= 1830))
length(which(as.character(kb$gatherings)!="" & kb$publication_year <= 1830)) / length(which(kb$publication_year <= 1830))
length(which(as.character(kb$gatherings)!="" & kb$publication_year <= 1830))
length(which(as.character(kb$gatherings)!="NA" & kb$publication_year <= 1830))
length(which(as.character(kb$gatherings)!="NA" & kb$publication_year <= 1830)) / length(which(kb$publication_year <= 1830))
length(which(kb$publication_year <= 1830))
install_github("ropensci/genderdata")
fennica <- readRDS("../../../Työ/Kungliga/Aineisto/Kungliga/df.fennica.Rds")
length(which(as.character(fennica$gatherings)!="NA" & fennica$publication_year <= 1830)) / length(which(fennica$publication_year <= 1830))
length(which(as.character(fennica$gatherings)!="NA" & fennica$publication_year <= 1830))
length(which(as.character(fennica$gatherings)!="NA" & fennica$publication_year <= 1900)) / length(which(fennica$publication_year <= 1900))
length(which(as.character(fennica$gatherings)!="NA" & fennica$publication_year <= 1900))
length(which(fennica$publication_year <= 1900))
source('~/GitHub/Gradu/run_svm.R')
source('~/GitHub/Gradu/run_svm_once.R')
run_svm_once(df=df[1000:2000], filenamestem="TEST_svm_final",training_percent = 100, features = feats_final[1000:2000])
run_svm_once(df=df[1000:2000,], filenamestem="TEST_svm_final",training_percent = 100, features = feats_final[1000:2000,])
run_svm_once(df=df[1000:10000,], filenamestem="TEST_svm_final",training_percent = 100, features = feats_final[1000:10000,])
l <- "<data><text>Manescal, Miguel, active 1667-1720?</text><sources><s>ISNI</s><sid>ISNI|0000000069929572</sid><s>LC</s><sid>LC|no2014112742</sid></sources></data>"
grep("<data><text>[^<]*<[/]<text><sources><s>")
grep("<data><text>[^<]*<[/]<text><sources><s>", l)
grep("<data><text>[^<]*<[/]text><sources><s>", l)
grep("<data><text>[^<]*<[/]text><sources><s>[^<]*<[/]s>", l)
grep("<data><text>[^<]*<[/]text><sources><s>[^<]*<[/]s><sid>LC", l)
grep("<data><text>[^<]*<[/]text><sources><s>[^<]*<[/]s><sid>ISNI", l)
grep("<data><text>([^<]*)<[/]text><sources><s>[^<]*<[/]s><sid>ISNI", l)
gsub("<data><text>([^<]*)<[/]text><sources><s>[^<]*<[/]s><sid>ISNI", "\\1",l)
str_extract("<data><text>([^<]*)<[/]text><sources><s>[^<]*<[/]s><sid>ISNI", "\\1",l)
str_extract(l, "<data><text>([^<]*)<[/]text><sources><s>[^<]*<[/]s><sid>ISNI", "\\1")
str_extract(l, "<data><text>([^<]*)<[/]text><sources><s>[^<]*<[/]s><sid>ISNI")
str_extract("<data><text>([^<]*)<[/]text><sources><s>[^<]*<[/]s><sid>ISNI", l)
str_match(l, "<data><text>([^<]*)<[/]text><sources><s>[^<]*<[/]s><sid>ISNI")
str_match(l, "<data><text>([^<]*)<[/]text><sources><s>[^<]*<[/]s><sid>ISNI")[2]
source('~/GitHub/Gradu/run_C45.R')
install.packages("tibble")
install.packages("rlang")
source('~/GitHub/Gradu/run_C45.R')
run_c45_once(df = df[1000:2000,], features = feats_final[1000:2000,], filenamestem = "TEST_C45")
source("run_C45_once.R")
source("run_C45.R")
source("run_C45_once.R")
run_c45_once(df = df[1000:2000,], features = feats_final[1000:2000,], filenamestem = "TEST_C45")
run_C45_once(df = df[1000:2000,], features = feats_final[1000:2000,], filenamestem = "TEST_C45")
names(feats_final)
feats_c45 <- feats_final[,c(40:50,length(feats_final))]
run_C45_once(df = df[1000:2000,], features = feats_final[1000:2000,], filenamestem = "TEST_C45")
feats_c45 <- feats_final[,c(20:30,length(feats_final))]
names(feats_c45)
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
feats_c45 <- feats_final[,c(40:50,length(feats_final))]
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
names(feats_c45$is_poetry)
names(feats_c45)
feats_c45$is_poetry[1:10]
feats_c45[1000,]
feats_basic_bow19$basic_word_length[1000]
feats_basic_bow19$basic_adjectives[1000]
nrow(feats_c45)
feats_c45$basic_adjectives[1000]
feats_c45$basic_adverbs[1000]
names(feats_c45)
feats_c45 <- feats_final[,c(41,length(feats_final))]
unique(feats_c45$basic_adverbs)
feats_final[1:10,]
feats_c45[1:10,]
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
is_poetry[0]
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
unique(is_poetry)
is_poetry[1]
length(which(is_poetry=="FALSE"))
length(which(is_poetry=="TRUE"))
length(which(is_poetry=="FALSE"))
nrow(Features)
nrow(features)
nrow(features.split$features1)
is_poetry[which(is_poetry=="TRUE")] <- TRUE
unique(is_poetry)
is_poetry <- as.logical(is_poetry   )
unique(is_poetry)
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
is_poetry <- as.character(is_poetry)
is_poetry[1:10]
is_poetry <- as.logical(is_poetry)
features$is_poetry <- is_poetry
features[1:10,]
names(features)
names(feats_c45)
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
names(features)
names(features.split$features1)
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
names(df.genres.sets$training)
debugSource('~/GitHub/Gradu/run_svm_once.R')
run_svm_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
names(df.genres.sets$training)
debugSource('~/GitHub/Gradu/run_svm_once.R')
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
names(df.genres.sets$training)
source('~/GitHub/Gradu/run_C45_once.R')
debugSource('~/GitHub/Gradu/run_C45_once.R')
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
names(features.training)
debugSource('~/GitHub/Gradu/run_C45_once.R')
run_C45_once(df = df[1000:2000,], features = feats_c45[1000:2000,], filenamestem = "TEST_C45")
names(features.training)
names(features.split$features1)
source('~/GitHub/Gradu/run_C45_once.R')
source('~/GitHub/Gradu/run_svm_once.R')
feats_final$is_poetry[1:10]
source('~/GitHub/Gradu/run_rf.R')
qqq <- run_rf_once(df=df,
features=feats_final,
filenamestem = "FINAL_ntree50_control",
ntree=50,
mtry=10,
training_percent=100)
source('~/GitHub/Gradu/run_rf.R')
qqq <- run_rf_once(df=df,
features=feats_final,
filenamestem = "FINAL_ntree50_control",
ntree=50,
mtry=10,
training_percent=100)
debugSource('~/GitHub/Gradu/run_rf.R')
qqq <- run_rf_once(df=df,
features=feats_final,
filenamestem = "FINAL_ntree50_control",
ntree=50,
mtry=10,
training_percent=100)
prediction_no_cutoff[1:10]
levels(is_poetry)
levels(is_poetry2)
retRF_no_cutoff$y[1:10]
length(retRF_no_cutoff$y)
is_poetry[1:10]
features$is_poetry[1:10]
ratio_is_poetry
levels(features$is_poetry)
levels(features$is_poetry) <- gsub("FALSE", "NONPOETRY", levels(features$is_poetry))
levels(features$is_poetry) <- gsub("TRUE", "POETRY", levels(features$is_poetry))
levels(features$is_poetry)
levels(is_poetry)
is_poetry <- rbindlist(features.split[-set_no], use.names=TRUE)$is_poetry
debugSource('~/GitHub/Gradu/run_rf.R')
qqq <- run_rf_once(df=df,
features=feats_final,
filenamestem = "FINAL_ntree50_control",
ntree=50,
mtry=10,
training_percent=100)
levels(prediction_no_cutoff$y)
levels(prediction_no_cutoff)
levels(is_poetry2)
source('~/GitHub/Gradu/run_rf.R')
qqq <- run_rf_once(df=df,
features=feats_final,
filenamestem = "FINAL_ntree50_control",
ntree=50,
mtry=10,
training_percent=100)
debugSource('~/GitHub/Gradu/run_oner.R')
run_oner_once(df=df[1000:2000,], features=feats_final[1000:2000,], filenamestem = "TEST_FINAL_oneR")
debugSource('~/GitHub/Gradu/run_oner.R')
run_oner_once(df=df[1000:2000,], features=feats_final[1000:2000,], filenamestem = "TEST_FINAL_oneR")
unique(features$is_poetry)
source('~/GitHub/Gradu/run_oner_once.R')
run_oner_once(df=df[1000:2000,], features=feats_final[1000:2000,], filenamestem = "TEST_FINAL_oneR")
source('~/GitHub/Gradu/run_oner.R')
source('~/GitHub/Gradu/run_oner_once.R')
run_oner_once(df=df[1000:2000,], features=feats_final[1000:2000,], filenamestem = "TEST_FINAL_oneR")
debugSource('~/GitHub/Gradu/run_oner.R')
run_oner_once(df=df[1000:2000,], features=feats_final[1000:2000,], filenamestem = "TEST_FINAL_oneR")
levels(pred2)
levels(is_poetry2)
levels(pred2)
length(which(pred2=="UNSEEN"
))
which(pred2=="UNSEEN")
length(pred2)
debugSource('~/GitHub/Gradu/run_oner.R')
))
run_oner_once(df=df[1000:2000,], features=feats_final[1000:2000,], filenamestem = "TEST_FINAL_oneR")
levels(pred2)
run_oner_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_oneR")
source('~/GitHub/Gradu/run_oner.R')
source('~/GitHub/Gradu/run_oner_once.R')
run_oner_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_oneR")
source('~/GitHub/Gradu/run_oner.R')
source('~/GitHub/Gradu/run_oner_once.R')
source('~/GitHub/Gradu/run_oner.R')
run_oner_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_oneR")
source('~/GitHub/Gradu/run_oner_once.R')
source('~/GitHub/Gradu/run_oner.R')
run_oner_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_oneR")
x
debugSource('~/GitHub/Gradu/convert_cm_to_df.R')
source('~/GitHub/Gradu/run_oner_once.R')
run_oner_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_oneR")
ret
which(is.na(ret))
all_names
which(is.nan(ret))
which(is.nan(ret) | (ret=="NaN"))
which(is.nan(ret) || (ret=="NaN"))
which(is.na(ret) || (ret=="NaN"))
which(is.na(ret) | (ret=="NaN"))
source('~/GitHub/Gradu/convert_cm_to_df.R')
source('~/GitHub/Gradu/run_oner_once.R')
run_oner_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_oneR")
debugSource('~/GitHub/Gradu/run_oner_once.R')
run_oner_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_oneR")
aggr
source('~/GitHub/Gradu/run_oner_once.R')
run_oner_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_oneR")
source('~/GitHub/Gradu/run_oner.R')
source('~/GitHub/Gradu/run_oner_once.R')
qqq <- run_LDA_once(df=df[1000:2000,], features=feats_final[1000:2000,], filenamestem = "TEST_FINAL_LDA")
source('~/GitHub/Gradu/run_LDA.R')
source('~/GitHub/Gradu/run_LDA_once.R')
qqq <- run_LDA_once(df=df[1000:2000,], features=feats_final[1000:2000,], filenamestem = "TEST_FINAL_LDA")
qqq <- run_LDA_once(df=df[1000:20000,], features=feats_final[1000:20000,], filenamestem = "TEST_FINAL_LDA")
qqq <- run_LDA_once(df=df[1000:200000,], features=feats_final[1000:200000,], filenamestem = "TEST_FINAL_LDA")
length(feats_final)
debugSource('~/GitHub/Gradu/run_LDA.R')
qqq <- run_LDA_once(df=df[1000:200000,], features=feats_final[1000:200000,], filenamestem = "TEST_FINAL_LDA")
features[27]
features[27,]
features[,27]
features[,28]
features[27,]
features[28,]
LDA_model <- lda(is_poetry ~ ., data=features)
features[30,]
features[27,]
names(features[27])
names(features)[27]
names(features)[30]
nrow(features)
features[1:10,c(27,30)]
features[1:10,c(27, 30, 33, 34, 35, 38, 41, 44, 48, 51, 52, 55)]
feats <- features[,c(!27)]
length(feats)
feats <- features[,c(1:26,28:length(features))]
length(feats)
LDA_model <- lda(is_poetry ~ ., data=feats)
names(feats)
feats <- data.frame(features[,c(1:26,28:length(features))])
LDA_model <- lda(is_poetry ~ ., data=feats)
feats <- features
feats[27] <- NULL
LDA_model <- lda(is_poetry ~ ., data=feats)
names(feats)
str(feats)
length(feats)
feats[27] <- NULL
length(feats)
feats[[27]] <- NULL
length(feats)
LDA_model <- lda(is_poetry ~ ., data=feats)
str(feats)
source('~/GitHub/Gradu/run_LDA.R')
source('~/GitHub/Gradu/run_C45.R')
source('~/GitHub/Gradu/run_C45_once.R')
qqq <- run_C45_once(df=df[1000:2000,], features = feats_final[1000:2000,], filenamestem = "TEST_FINAL_c45", training_percent = 100)
qqq <- run_naivebayes_once(df=df[1000:2000,], features=feats[1000:2000,])
source('~/GitHub/Gradu/run_naivebayes_once.R')
qqq <- run_naivebayes_once(df=df[1000:2000,], features=feats[1000:2000,])
source('~/GitHub/Gradu/run_naivebayes.R')
source('~/GitHub/Gradu/run_naivebayes_once.R')
qqq <- run_naivebayes_once(df=df[1000:2000,], features=feats[1000:2000,])
debugSource('~/GitHub/Gradu/run_naivebayes_once.R')
qqq <- run_naivebayes_once(df=df[1000:2000,], features=feats[1000:2000,])
length(aggr)
length(feats)
names(feats)
qqq <- run_naivebayes_once(df=df[1000:2000,], features=feats[1000:2000,])
df.genres.sets <- get_training_and_testing_sets(features=feats,
training_percent=50,
filenamestem=filenamestem,
load=FALSE)
names(feats)
names(features)
qqq <- run_naivebayes_once(df=df[1000:2000,], features=feats_final[1000:2000,])
